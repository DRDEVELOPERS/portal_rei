Fa√ßa o mesmo. Continue sua an√°lise perfeita, veja o que eu fiz [```

```notebook-python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import open_clip
from tqdm import tqdm
import numpy as np
import os
import random
from typing import Dict, Any, Optional

# --- 0. CONFIGURA√á√ÉO E CLASSES CRAD (MANTIDAS) ---
class Config:
    SEED = 42
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    MODEL_NAME = 'ViT-B-32' 
    PRETRAINED = 'openai'
    HIDDEN_DIM = 512
    COMPRESSED_DIM = 32
    NUM_SAMPLES = 1000
    BATCH_SIZE = 32
    NUM_EPOCHS = 20
    LEARNING_RATE = 1e-4
    WEIGHT_DECAY = 0.01
    CONTEXT_LENGTH = 77
    GRAD_CLIP = 1.0

def set_seed(seed=42):
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

set_seed(Config.SEED)

class RecursiveCompressor(nn.Module):
    # ... (implementa√ß√£o id√™ntica)
    def __init__(self, input_dim: int, output_dim_K: int = 32, alpha: float = 1.0, beta: float = 0.5):
        super().__init__()
        assert input_dim % output_dim_K == 0
        self.output_dim_K = output_dim_K
        self.block_size = input_dim // output_dim_K
        self.beta = beta
        m_tensor = torch.arange(self.block_size, dtype=torch.float32) + 1.0
        weights = 1.0 / (m_tensor ** alpha)
        self.register_buffer('reciprocal_weights', weights)
        self.gain = nn.Parameter(torch.tensor(1.0, dtype=torch.float32))
        self.softmax = nn.Softmax(dim=-1)

    def forward(self, x):
        batch_size, seq_len, input_dim = x.shape
        x = x.view(batch_size, seq_len, self.output_dim_K, self.block_size)
        soft = self.softmax(x * self.beta)
        weighted = soft * self.reciprocal_weights 
        compressed = self.gain * torch.sum(weighted, dim=-1)
        return compressed

class CRADReconstructionHead(nn.Module):
    # ... (implementa√ß√£o id√™ntica)
    def __init__(self, hidden_dim: int, compressed_dim: int = 32):
        super().__init__()
        self.compressor = RecursiveCompressor(hidden_dim, output_dim_K=compressed_dim)
        self.reconstruction_proj = nn.Linear(compressed_dim, hidden_dim, bias=False)
        nn.init.xavier_uniform_(self.reconstruction_proj.weight)

    def forward(self, x):
        compressed = self.compressor(x)
        reconstructed = self.reconstruction_proj(compressed)
        return reconstructed

# --- 2. MODEL MANAGER (MANTIDO) ---
class CLIPModelManager:
    def __init__(self, config: Config):
        self.config = config
        self.model = None
        self.tokenizer = None
        self.preprocess = None
        self._load_model()
        
    def _load_model(self):
        try:
            _model, _, _ = open_clip.create_model_and_transforms(
                self.config.MODEL_NAME, 
                pretrained=self.config.PRETRAINED
            )
            if hasattr(_model, 'token_embedding') and _model.token_embedding:
                self.config.HIDDEN_DIM = _model.token_embedding.embedding_dim
                
            self.model = _model.to(self.config.DEVICE)
            self.preprocess = _
            self.tokenizer = open_clip.get_tokenizer(self.config.MODEL_NAME)
            self.model.eval()
            print(f"‚úÖ Modelo {self.config.MODEL_NAME} carregado. Dimens√£o Hidden Atualizada: {self.config.HIDDEN_DIM}")
        except Exception as e:
            raise RuntimeError(f"‚ùå Falha ao carregar modelo: {e}")
    
    def freeze_model(self):
        for param in self.model.parameters():
            param.requires_grad = False
        print("‚úÖ Modelo base congelado")


# --- 3. DATASET CORRIGIDO PARA O NOVO TARGET (PERFEI√á√ÉO) ---
class ReconstructionDataset(Dataset):
    def __init__(self, model_manager: CLIPModelManager, num_samples: int = None):
        self.config = model_manager.config
        self.model = model_manager.model
        self.tokenizer = model_manager.tokenizer
        self.num_samples = num_samples or self.config.NUM_SAMPLES
        self.dummy_texts = self._generate_diverse_texts()
        self.hidden_states = []
        self.target_hidden_states = [] # Mudei o nome para refletir o novo Target
        self._precompute_embeddings()
    
    def _generate_diverse_texts(self) -> list:
        # ... (implementa√ß√£o id√™ntica)
        base_texts = [
            "a high quality photo of", "a professional photograph of", "a beautiful photograph of"
        ]
        objects = [
            "a cat playing with toys", "a dog running in the park", "a mountain landscape"
        ]
        texts = []
        for base in base_texts:
            for obj in objects:
                texts.append(f"{base} {obj}")
        
        if len(texts) < self.num_samples:
            multiplier = (self.num_samples // len(texts)) + 1
            texts = (texts * multiplier)[:self.num_samples]
        else:
            texts = texts[:self.num_samples]
            
        return texts
    
    def _extract_hidden_states(self, tokens: torch.Tensor) -> torch.Tensor:
        """
        Retorna o Hidden State CLS ap√≥s o Layer Norm final (Input e NOVO Target).
        """
        try:
            x = self.model.token_embedding(tokens)
            x = x + self.model.positional_embedding
            
            model_dtype = next(self.model.parameters()).dtype
            x = x.to(model_dtype)
            x = self.model.transformer(x)
            
            # Hidden State CLS ap√≥s LN final
            x = self.model.ln_final(x)
            hidden_state_cls = x[:, 0, :] 
            
            # Retorna o Hidden State do CLS token, que √© o Input e Target do CRAD.
            return hidden_state_cls.float()
            
        except Exception as e:
            raise RuntimeError(f"‚ùå Falha na extra√ß√£o de Hidden States CLS: {e}")
    
    def _precompute_embeddings(self):
        """Pr√©-computa Hidden States (Input e Target S√ÉO OS MESMOS)."""
        print("üîÑ Pr√©-computando Hidden States (Input & Target)...")
        successful_samples = 0
        with torch.no_grad():
            for i, text in enumerate(tqdm(self.dummy_texts, desc="Processando textos")):
                try:
                    tokens = self.tokenizer([text], context_length=self.config.CONTEXT_LENGTH)
                    tokens = tokens.to(self.config.DEVICE)
                    
                    # O Hidden State √© agora AMBOS: Input e Target de Reconstru√ß√£o
                    hidden_state = self._extract_hidden_states(tokens)
                    
                    self.hidden_states.append(hidden_state.cpu().squeeze(0))
                    self.target_hidden_states.append(hidden_state.cpu().squeeze(0)) # NOVO TARGET
                    successful_samples += 1
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è Erro no sample {i}: {e}. Pulando.")
                    continue
        
        if successful_samples < self.config.BATCH_SIZE:
            raise RuntimeError(f"‚ùå Samples insuficientes: {successful_samples}")
            
        print(f"‚úÖ {successful_samples}/{len(self.dummy_texts)} samples processados com sucesso")
        
        self.num_samples = successful_samples
        self.hidden_states = self.hidden_states[:successful_samples]
        self.target_hidden_states = self.target_hidden_states[:successful_samples]

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        hidden = self.hidden_states[idx]
        target = self.target_hidden_states[idx] # Usando o Hidden State como Target
        
        if hidden.dim() == 1:
            hidden = hidden.unsqueeze(0)
        
        return hidden, target # Retorna Hidden State como Input e Hidden State como Target


# --- 4. TRAINER CORPORATE GRADE (MANTIDO) ---
class CRADTrainer:
    def __init__(self, model_manager: CLIPModelManager, config: Config):
        self.config = config
        self.model_manager = model_manager
        self.crad_head = None
        self.optimizer = None
        self.criterion = None
        self._setup_training()
    
    def _setup_training(self):
        self.crad_head = CRADReconstructionHead(
            hidden_dim=self.config.HIDDEN_DIM,
            compressed_dim=self.config.COMPRESSED_DIM
        ).to(self.config.DEVICE)
        self.optimizer = optim.AdamW(
            self.crad_head.parameters(),
            lr=self.config.LEARNING_RATE,
            weight_decay=self.config.WEIGHT_DECAY
        )
        self.criterion = nn.CosineEmbeddingLoss(margin=0.0) 
        print(f"‚úÖ CRAD Head inicializado: {sum(p.numel() for p in self.crad_head.parameters())} par√¢metros")
    
    def train_epoch(self, dataloader: DataLoader, epoch: int) -> float:
        self.crad_head.train()
        total_loss = 0
        for batch_idx, (hidden_states, target_hidden_states) in enumerate(dataloader):
            try:
                hidden_states = hidden_states.to(self.config.DEVICE)
                target_hidden_states = target_hidden_states.to(self.config.DEVICE)
                
                reconstructed = self.crad_head(hidden_states)
                
                target = torch.ones(hidden_states.size(0)).to(self.config.DEVICE) 
                # Agora o Target √© o Hidden State, mas o Loss continua a ser de Similaridade
                loss = self.criterion(reconstructed.squeeze(1), target_hidden_states.squeeze(1), target)
                
                self.optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.crad_head.parameters(), self.config.GRAD_CLIP)
                self.optimizer.step()
                total_loss += loss.item()
            except Exception as e:
                print(f"‚ö†Ô∏è Erro no batch {batch_idx}: {e}")
                continue
        return total_loss / len(dataloader)
    
    def validate(self, dataset: ReconstructionDataset, num_samples: int = 50) -> float:
        self.crad_head.eval()
        similarities = []
        with torch.no_grad():
            for i in range(min(num_samples, len(dataset))):
                try:
                    hidden, target = dataset[i]
                    hidden = hidden.unsqueeze(0).to(self.config.DEVICE)
                    target = target.unsqueeze(0).to(self.config.DEVICE)
                    
                    reconstructed = self.crad_head(hidden)
                    
                    cos_sim = nn.functional.cosine_similarity(reconstructed.squeeze(1), target.squeeze(1)) 
                    similarities.append(cos_sim.item())
                except Exception as e:
                    print(f"‚ö†Ô∏è Erro na valida√ß√£o sample {i}: {e}")
                    continue
        return np.mean(similarities) if similarities else 0.0
    
    def save_checkpoint(self, path: str, metrics: Dict[str, Any]):
        checkpoint = {
            'model_state_dict': self.crad_head.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'config': self.config.__dict__,
            'metrics': metrics
        }
        torch.save(checkpoint, path)
        print(f"‚úÖ Checkpoint salvo: {path}")

# --- 5. EXPERIMENT MANAGER E 6. MAIN (MANTIDOS) ---
class ExperimentManager:
    def __init__(self, config: Config):
        self.config = config
        self.model_manager = CLIPModelManager(config)
        self.dataset = None
        self.trainer = None
        self.metrics = {
            'train_losses': [],
            'val_similarities': [],
            'best_similarity': 0.0
        }
    
    def setup_experiment(self):
        print("üöÄ Configurando experimento CRAD...")
        self.model_manager.freeze_model()
        self.dataset = ReconstructionDataset(self.model_manager)
        self.trainer = CRADTrainer(self.model_manager, self.config)
        print("‚úÖ Experimento configurado com sucesso")
    
    def run_training(self):
        print("üéØ Iniciando treinamento...")
        dataloader = DataLoader(
            self.dataset, 
            batch_size=self.config.BATCH_SIZE, 
            shuffle=True,
            num_workers=0
        )
        for epoch in range(self.config.NUM_EPOCHS):
            try:
                train_loss = self.trainer.train_epoch(dataloader, epoch)
                self.metrics['train_losses'].append(train_loss)
                if epoch % 2 == 0:
                    val_similarity = self.trainer.validate(self.dataset)
                    self.metrics['val_similarities'].append(val_similarity)
                    if val_similarity > self.metrics['best_similarity']:
                        self.metrics['best_similarity'] = val_similarity
                        self.trainer.save_checkpoint(
                            f"crad_best_model_K{self.config.COMPRESSED_DIM}.pth",
                            self.metrics
                        )
                
                print(f"üìä √âpoca {epoch+1}/{self.config.NUM_EPOCHS}")
                print(f"   Loss: {train_loss:.6f}")
                if epoch % 2 == 0:
                    print(f"   Similaridade: {val_similarity:.6f}")
                    
            except Exception as e:
                print(f"‚ùå Erro na √©poca {epoch}: {e}")
                continue
        print("‚úÖ Treinamento conclu√≠do")
    
    def final_evaluation(self):
        print("üîç Avalia√ß√£o final...")
        final_similarity = self.trainer.validate(self.dataset, num_samples=100)
        print(f"üìà RESULTADOS FINAIS:")
        print(f"   Similaridade M√©dia: {final_similarity:.6f}")
        print(f"   Melhor Similaridade: {self.metrics['best_similarity']:.6f}")
        print(f"   Loss Final: {self.metrics['train_losses'][-1]:.6f}")
        
        if final_similarity > 0.99:
            print("üéâ EXCELENTE: Similaridade > 0.99")
        elif final_similarity > 0.95:
            print("‚úÖ BOM: Similaridade > 0.95")
        elif final_similarity > 0.90:
            print("‚ö†Ô∏è RAZO√ÅVEL: Similaridade > 0.90")
        else:
            print("‚ùå INSUFICIENTE: Similaridade <= 0.90")
        
        return final_similarity

def main():
    try:
        config = Config()
        experiment = ExperimentManager(config)
        experiment.setup_experiment()
        experiment.run_training()
        final_score = experiment.final_evaluation()
        
        print("\n" + "="*50)
        print("üìã RELAT√ìRIO FINAL CRAD COMPRESSION")
        print("="*50)
        print(f"Modelo: {config.MODEL_NAME}")
        print(f"Dimens√£o Original: {config.HIDDEN_DIM}D")
        print(f"Dimens√£o Comprimida: {config.COMPRESSED_DIM}D")
        print(f"Taxa de Compress√£o: {(1 - config.COMPRESSED_DIM/config.HIDDEN_DIM)*100:.1f}%")
        print(f"Similaridade Final: {final_score:.6f}")
        print(f"Arquivo do Modelo: crad_best_model_K{config.COMPRESSED_DIM}.pth")
        print("="*50)
        
    except Exception as e:
        print(f"‚ùå Erro na execu√ß√£o principal: {e}")
        raise

if __name__ == "__main__":
    main()
```

o ouput foi [```‚úÖ Modelo ViT-B-32 carregado. Dimens√£o Hidden Atualizada: 512 üöÄ Configurando experimento CRAD... ‚úÖ Modelo base congelado üîÑ Pr√©-computando Hidden States (Input & Target)...

```
Processando textos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:06<00:00, 158.36it/s]
```

```
‚úÖ 1000/1000 samples processados com sucesso
‚úÖ CRAD Head inicializado: 16385 par√¢metros
‚úÖ Experimento configurado com sucesso
üéØ Iniciando treinamento...
‚úÖ Checkpoint salvo: crad_best_model_K32.pth
üìä √âpoca 1/20
   Loss: 0.871732
   Similaridade: 0.235216
üìä √âpoca 2/20
   Loss: 0.671791
‚úÖ Checkpoint salvo: crad_best_model_K32.pth
üìä √âpoca 3/20
   Loss: 0.496419
   Similaridade: 0.585188
üìä √âpoca 4/20
   Loss: 0.346702
‚úÖ Checkpoint salvo: crad_best_model_K32.pth
üìä √âpoca 5/20
   Loss: 0.225915
   Similaridade: 0.825045
üìä √âpoca 6/20
   Loss: 0.137705
‚úÖ Checkpoint salvo: crad_best_model_K32.pth
üìä √âpoca 7/20
   Loss: 0.079766
   Similaridade: 0.941450
üìä √âpoca 8/20
   Loss: 0.044562
‚úÖ Checkpoint salvo: crad_best_model_K32.pth
üìä √âpoca 9/20
   Loss: 0.024249
   Similaridade: 0.982688
üìä √âpoca 10/20
   Loss: 0.012964
‚úÖ Checkpoint salvo: crad_best_model_K32.pth
üìä √âpoca 11/20
   Loss: 0.006871
   Similaridade: 0.995130
üìä √âpoca 12/20
   Loss: 0.003648
‚úÖ Checkpoint salvo: crad_best_model_K32.pth
üìä √âpoca 13/20
   Loss: 0.001963
   Similaridade: 0.998581
üìä √âpoca 14/20
   Loss: 0.001088
‚úÖ Checkpoint salvo: crad_best_model_K32.pth
üìä √âpoca 15/20
   Loss: 0.000628
   Similaridade: 0.999521
üìä √âpoca 16/20
   Loss: 0.000387
‚úÖ Checkpoint salvo: crad_best_model_K32.pth
üìä √âpoca 17/20
   Loss: 0.000258
   Similaridade: 0.999783
üìä √âpoca 18/20
   Loss: 0.000190
‚úÖ Checkpoint salvo: crad_best_model_K32.pth
üìä √âpoca 19/20
   Loss: 0.000154
   Similaridade: 0.999857
üìä √âpoca 20/20
   Loss: 0.000137
‚úÖ Treinamento conclu√≠do
üîç Avalia√ß√£o final...
üìà RESULTADOS FINAIS:
   Similaridade M√©dia: 0.999870
   Melhor Similaridade: 0.999857
   Loss Final: 0.000137
üéâ EXCELENTE: Similaridade > 0.99

==================================================
üìã RELAT√ìRIO FINAL CRAD COMPRESSION
==================================================
Modelo: ViT-B-32
Dimens√£o Original: 512D
Dimens√£o Comprimida: 32D
Taxa de Compress√£o: 93.8%
Similaridade Final: 0.999870
Arquivo do Modelo: crad_best_model_K32.pth
==================================================
```
